# Асинхронный парсер документации Python с помощью Scrapy

Основной задачей парсера является формирование списка статусов PEP документов

## Используемые технологии

- Python
- Scrapy

## Как пользоваться
- Скачать проект:
```
https://github.com/SergeyViskov/scrapy_parser_pep.git
```
- Перейти в директорию проекта:
```
cd scrapy_parser_pep
```
- Создать виртуальное окружение:
```
python -m venv venv
```
- Активировать виртуальное окружение:
```
source venv/Scripts/activate
```
- Установить зависимости:
```
pip install -r requirements.txt
```
- Запуск парсера:
```
scrapy crawl pep
```

### Результат работы
Файл pep_date.csv в котором выводится список всех PEP документов

Формат выдачи:
```
Номер | Название | Статус
```

Файл status_summary.csv в котором выводится таблица с подсчетом
количества PEP документов в каждом статусе и общее количество документов

Формат выдачи:
```
Статус | Количество
```

### Об авторе:
    
    Висков Сергей Николаевич
    Ученик Яндекс-практикума, когорта №9 +